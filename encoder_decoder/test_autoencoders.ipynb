{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "# import untils  # Provided utility\n",
    "# from COBWEBNN import CobwebNN, CobwebNNTreeLayer, TestModel\n",
    "from torchvision import datasets, transforms\n",
    "from resnet_encoder import Encoder, BasicBlockEnc\n",
    "from restnet_decoder import Decoder, BasicBlockDec\n",
    "from resnet_using_light_basic_block_encoder import LightEncoder, LightBasicBlockEnc\n",
    "from resnet_using_light_basic_block_decoder import LightDecoder, LightBasicBlockDec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from classes.resnet_autoencoder import AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cuda\n",
    "x = torch.tensor([1, 2, 3]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = True\n",
    "dataset_class = datasets.MNIST\n",
    "mnist_transform = [transforms.ToTensor()]\n",
    "# add normalization to the transform list such that all values are strictly greater than 0\n",
    "# mnist_transform.append(transforms.Lambda(lambda x: x + 1e-5))\n",
    "# normalize the data\n",
    "# mnist_transform.append(transforms.Normalize((0.1307,), (0.3081,)))\n",
    "\n",
    "dataset_transform = transforms.Compose(mnist_transform)\n",
    "mnist_train = dataset_class('data/MNIST', train=True, download=download, transform=dataset_transform)\n",
    "mnist_test = dataset_class('data/MNIST', train=False, download=download, transform=dataset_transform)\n",
    "\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "        # self.encoder = Encoder(BasicBlockEnc, [2, 2, 2, 2])\n",
    "        # self.decoder = Decoder(BasicBlockDec, [2, 2, 2, 2])\n",
    "        self.encoder = LightEncoder(LightBasicBlockEnc, [2, 2, 2]) \n",
    "        # projection_dim = 32\n",
    "        self.n_hidden = 32\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(64*7*7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.n_hidden),\n",
    "            # nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.n_hidden, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 64*7*7),\n",
    "            nn.Unflatten(1, (64, 7, 7)),\n",
    "            LightDecoder(LightBasicBlockDec, [2, 2, 2]),\n",
    "        )\n",
    "\n",
    "        # self.fc_encoder = nn.Linear(64*8*8, 512)\n",
    "        # self.fc_decoder = nn.Linear(512, 64*8*8)\n",
    "        # decoder MLP\n",
    "        # self.decoder = nn.Sequential(\n",
    "        #     nn.Linear(512, 64*2*2),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Linear(64*2*2, 64*4*4),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Linear(64*4*4, 3*32*32),\n",
    "        #     nn.ReLU(True)\n",
    "        # )\n",
    "\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # self.ConTrans2d = nn.ConvTranspose2d(64, 64, 8, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z = self.projection(x.view(x.size(0), -1))\n",
    "        # print(x.shape)\n",
    "        \n",
    "        # x = self.avgpool(x).view(x.size(0), -1)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # x = self.fc_encoder(x)\n",
    "        # print(x.shape)\n",
    "        # x = self.fc_decoder(x).view(x.size(0), 64, 8, 8)\n",
    "\n",
    "        # x = self.ConTrans2d(x)\n",
    "        # print(x.shape)\n",
    "        # x = self.fc_decoder(x)\n",
    "        # x = x.view(x.size(0), 64, 8, 8)\n",
    "        # z = self.de_projection(z)\n",
    "        x = self.decoder(z)\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction(model, test_data, n_data=64, device='cuda', epochs=100):\n",
    "    model.eval()\n",
    "    test_loader = DataLoader(test_data, batch_size=n_data, shuffle=True)\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(test_loader):\n",
    "            x = x.to(device)\n",
    "            x = x.expand(-1, 3, -1, -1)\n",
    "            x_recon = model(x)\n",
    "            break\n",
    "    model.train()\n",
    "    # untils.visualize(x, x_recon, n_data)\n",
    "    # 8*8 subplots\n",
    "    fig, axs = plt.subplots(8, 8, figsize=(16, 16))\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            axs[i, j].imshow(x_recon[i*8+j].cpu().permute(1, 2, 0))\n",
    "            axs[i, j].axis('off')\n",
    "    # plt.show()\n",
    "    # save image to file\n",
    "    plt.savefig(f'./ae_recon.png')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:12<00:00, 38.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.009492166340351105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1078343].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1404964].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1282963].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.2712901].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1582433].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1387092].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.2028837].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.17121].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1032919].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1717522].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1128861].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1087358].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1651543].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1228132].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1544966].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.090299].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0967282].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1291316].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.133253].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0715771].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1588405].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1281627].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.187142].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1306375].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.128397].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0083312].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1040332].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1918118].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1745541].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1209482].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.10837].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1467031].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1125633].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0756817].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.131888].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1281481].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1132181].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1015233].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1777911].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1843032].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1587409].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1148062].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1485671].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0814614].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.2026733].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.2002358].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0876483].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1246966].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0399096].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0967448].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1770256].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1730618].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1714034].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1705561].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.2049105].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.095868].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.155415].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1430937].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0869389].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0964683].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1274475].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.1311283].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.113485].\n",
      "100%|██████████| 469/469 [00:12<00:00, 37.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.00533831212669611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 285/469 [00:07<00:04, 39.12it/s]"
     ]
    }
   ],
   "source": [
    "# train and test the model\n",
    "model = AE().to(device)\n",
    "# .to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "n_epochs = 10\n",
    "loss_fn = nn.MSELoss()\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for i, (x, _) in enumerate(tqdm(mnist_train_loader)):\n",
    "        x = x.to(device)\n",
    "        # expand it as a 3 channel image\n",
    "        x = x.expand(-1, 3, -1, -1)\n",
    "        # print(x.min(), x.max())\n",
    "        optimizer.zero_grad()\n",
    "        x_recon = model(x)\n",
    "        # print(x_recon.min(), x_recon.max())\n",
    "        # break\n",
    "        loss = loss_fn(x_recon, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "    if epoch % 10 == 0:\n",
    "        visualize_reconstruction(model, mnist_test, 64, device, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
