{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch                              # PyTorch core library\n",
    "import torch.nn as nn                     # For building neural network modules\n",
    "import torch.optim as optim               # For optimization algorithms\n",
    "from torch.utils.data import DataLoader   # For creating data loaders\n",
    "from torchvision import datasets, transforms  # For MNIST dataset and image transformations\n",
    "from torchvision.utils import save_image # For saving generated images\n",
    "\n",
    "# Check if CUDA (GPU) is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 73550441.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2408982.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 19582218.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 6731635.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "batch_size = 128      # Number of images per batch\n",
    "epochs = 10           # Number of training epochs\n",
    "learning_rate = 1e-3  # Learning rate for the optimizer\n",
    "log_interval = 100    # How often to log training progress\n",
    "\n",
    "# Define a transform to convert images to tensor (values in [0,1])\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Download and load the MNIST training dataset\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data',         # Directory to store data\n",
    "    train=True,            # Use the training split\n",
    "    download=True,         # Download if not already available\n",
    "    transform=transform    # Apply the transformation\n",
    ")\n",
    "\n",
    "# Download and load the MNIST test dataset (not used in training here, but available)\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create data loaders for training and testing datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Variational Autoencoder (VAE) model as a subclass of nn.Module\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        # Encoder layers:\n",
    "        self.fc1 = nn.Linear(784, 400)   # Fully connected layer from input (28x28=784) to hidden dimension 400\n",
    "        self.fc21 = nn.Linear(400, 20)   # Layer to output the mean (mu) of the latent space\n",
    "        self.fc22 = nn.Linear(400, 20)   # Layer to output the log variance (logvar) of the latent space\n",
    "\n",
    "        # Decoder layers:\n",
    "        self.fc3 = nn.Linear(20, 400)    # Fully connected layer from latent dimension 20 to hidden dimension 400\n",
    "        self.fc4 = nn.Linear(400, 784)   # Layer to output the reconstructed image (flattened)\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through a fully connected layer and then splitting\n",
    "        into mean and log variance vectors.\n",
    "        \"\"\"\n",
    "        h1 = torch.relu(self.fc1(x))   # Apply ReLU activation after the first layer\n",
    "        return self.fc21(h1), self.fc22(h1)  # Return the mean and log variance\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from N(0,1).\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)      # Compute the standard deviation\n",
    "        eps = torch.randn_like(std)        # Sample random noise from a standard normal distribution\n",
    "        return mu + eps * std              # Return the sampled latent vector\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decodes the latent vector z to reconstruct the image.\n",
    "        \"\"\"\n",
    "        h3 = torch.relu(self.fc3(z))       # Apply ReLU activation after the first decoder layer\n",
    "        return torch.sigmoid(self.fc4(h3)) # Apply sigmoid to ensure output is between 0 and 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass through the network.\n",
    "        \"\"\"\n",
    "        # Flatten the input image and encode it to obtain mean and log variance\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        # Sample a latent vector using the reparameterization trick\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        print(z.min(), z.max())\n",
    "        # Decode the latent vector to get the reconstructed image\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VAE model and move it to the appropriate device (CPU or GPU)\n",
    "model = VAE().to(device)\n",
    "\n",
    "# Set up the optimizer (Adam optimizer)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    Computes the VAE loss function as the sum of the reconstruction loss (BCE) and\n",
    "    the Kullback-Leibler divergence loss.\n",
    "    \"\"\"\n",
    "    # Flatten the input image for computing reconstruction loss\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    # Compute the KL divergence between the learned latent distribution and a standard normal distribution\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD  # Total loss\n",
    "\n",
    "def train(epoch):\n",
    "    \"\"\"\n",
    "    Trains the VAE for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0  # Initialize training loss for the epoch\n",
    "\n",
    "    # Loop over all batches in the training dataset\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)       # Move data to the device (GPU/CPU)\n",
    "        optimizer.zero_grad()        # Reset the gradients from the previous iteration\n",
    "\n",
    "        # Forward pass: compute reconstructed image, mean, and log variance\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "\n",
    "        # Compute the loss using the loss_function defined above\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()              # Backpropagate to compute gradients\n",
    "        train_loss += loss.item()    # Accumulate the batch loss\n",
    "        optimizer.step()             # Update the model parameters\n",
    "\n",
    "        # Log progress every 'log_interval' batches\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} \"\n",
    "                  f\"({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item() / len(data):.6f}\")\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}\")\n",
    "\n",
    "def generate_images(num_images=64, filename='sample.png'):\n",
    "    \"\"\"\n",
    "    Generates new images by sampling from the latent space and decoding them.\n",
    "    The generated images are saved as a grid in a single image file.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        # Sample latent vectors from a standard normal distribution\n",
    "        z = torch.randn(num_images, 20).to(device)\n",
    "        # Decode the latent vectors to generate images\n",
    "        sample = model.decode(z).cpu()\n",
    "        # Reshape and save the generated images in a grid\n",
    "        save_image(sample.view(num_images, 1, 28, 28), filename)\n",
    "        print(f\"Generated images saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.6934, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.3829, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 551.123291\n",
      "tensor(-3.2855, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6798, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7604, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2675, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5199, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8213, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6660, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0352, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.4893, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6281, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2769, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9335, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.6856, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.6726, device='cuda:0', grad_fn=<MinBackward1>) tensor(6.0590, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-8.5324, device='cuda:0', grad_fn=<MinBackward1>) tensor(8.7235, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-6.9397, device='cuda:0', grad_fn=<MinBackward1>) tensor(8.6211, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-8.1170, device='cuda:0', grad_fn=<MinBackward1>) tensor(10.4090, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-8.7362, device='cuda:0', grad_fn=<MinBackward1>) tensor(7.4368, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-9.1013, device='cuda:0', grad_fn=<MinBackward1>) tensor(7.9222, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-9.1678, device='cuda:0', grad_fn=<MinBackward1>) tensor(8.4939, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-6.4153, device='cuda:0', grad_fn=<MinBackward1>) tensor(6.8415, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-6.1059, device='cuda:0', grad_fn=<MinBackward1>) tensor(6.9170, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6860, device='cuda:0', grad_fn=<MinBackward1>) tensor(6.3657, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.8230, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.9580, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.5712, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.5845, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9696, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.8450, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-6.3801, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5693, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6362, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.4718, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9454, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.2910, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6871, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.9622, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.1810, device='cuda:0', grad_fn=<MinBackward1>) tensor(6.4397, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.8596, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.8473, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-6.1435, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.0264, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.1977, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6960, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.2418, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.5779, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2897, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.2131, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.6520, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.3994, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6417, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.1082, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.0519, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5753, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.1988, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3863, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1411, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.3404, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9805, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0867, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1483, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1539, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5271, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2527, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8998, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.7035, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3791, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.8035, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6760, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1945, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7270, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.0101, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.7270, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.2009, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.2517, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.4964, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5517, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.9109, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5849, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.4148, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6304, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6942, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3571, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.3194, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8638, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.7875, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.6020, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.1791, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2262, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.0531, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3265, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5849, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8152, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0795, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.2128, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.1102, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9544, device='cuda:0', grad_fn=<MinBackward1>) tensor(6.1111, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3494, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9894, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.3341, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3222, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6863, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3561, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5054, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.8957, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.3051, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.8919, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9826, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.9108, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.0506, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6406, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.4822, device='cuda:0', grad_fn=<MinBackward1>) tensor(6.0948, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.0714, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.9514, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4221, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1314, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9196, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.8617, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0412, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5919, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.7804, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.1705, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4527, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5508, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9876, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.9720, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6055, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0607, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3782, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3284, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.7395, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6434, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4532, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9993, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2245, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6162, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0467, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9933, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5175, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2936, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2684, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9116, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.6370, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9353, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7462, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7996, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8165, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8374, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9101, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.4696, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0030, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0113, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2464, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7554, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1591, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2342, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0442, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0309, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9670, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.4125, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6635, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3262, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9489, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3202, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9358, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9717, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2370, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7812, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.4687, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7618, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8746, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2784, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.8096, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.8089, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6777, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.4351, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1367, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1264, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0976, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3714, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2166, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5198, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1565, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0633, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2188, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6912, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 186.479309\n",
      "tensor(-4.7145, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3074, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9229, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9507, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4701, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.7531, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1743, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5251, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5315, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2001, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.7364, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5665, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1068, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3724, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8543, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8958, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5881, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7029, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.4959, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1458, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6448, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7228, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2513, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0377, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4749, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2069, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5265, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8490, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1554, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1326, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2193, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2050, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0730, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2962, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4996, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.4241, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6406, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7002, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0473, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0347, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7869, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9227, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1980, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7733, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1128, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9171, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8644, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5942, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0124, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1526, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.7330, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5066, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7605, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.3319, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2762, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1157, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6433, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7727, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8265, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6478, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2543, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8398, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7025, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7977, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7889, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1079, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5239, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7478, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2663, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2532, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2529, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0522, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6938, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6063, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6294, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0246, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5626, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0595, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6253, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7181, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1666, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2454, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3055, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1265, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8561, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1138, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5437, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6960, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6901, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.4686, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9976, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5851, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8884, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0222, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1544, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3094, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0474, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2519, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9242, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1236, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4044, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7464, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6334, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1401, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7069, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.4984, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6302, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7585, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7332, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6641, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0794, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0909, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4748, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5195, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0587, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0191, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9449, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9981, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0082, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2173, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3902, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5451, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4415, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6959, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6352, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0269, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5753, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9390, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4369, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5685, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8850, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.4849, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5910, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7796, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8346, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0215, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8785, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2380, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1263, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8497, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2174, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5146, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9025, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7108, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7526, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7212, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3076, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0710, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0119, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9721, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7628, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8686, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7041, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3439, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9678, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1300, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6466, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0399, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2700, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9130, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5834, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0633, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8012, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6553, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2662, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8614, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0623, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8095, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8055, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2916, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6160, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8939, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9650, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0056, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0656, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0803, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8922, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7116, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6538, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8443, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0851, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9132, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5300, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3760, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1364, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6056, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8432, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5626, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9560, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0132, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.3648, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6358, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0161, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9832, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0488, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0609, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5285, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8442, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2814, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6749, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 152.819351\n",
      "tensor(-4.1689, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5836, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0197, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6567, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8423, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7065, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7216, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0342, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9313, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1963, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6579, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8166, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3551, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5655, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4787, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2171, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2741, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6693, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2229, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9772, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9855, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5646, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6428, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2302, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9754, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3560, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7472, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9045, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5733, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3451, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.4572, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8932, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9149, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9057, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8921, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2705, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7370, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8385, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2420, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7780, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3194, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5676, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9547, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3192, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4687, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8661, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3184, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8362, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9497, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6968, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7986, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5199, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8258, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8107, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4311, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8567, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.4986, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6997, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7996, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.4997, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.0876, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9054, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4267, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7586, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2766, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0565, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1339, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8352, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3412, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8410, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3796, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3651, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0658, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6565, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0963, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1785, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5251, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.5850, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8527, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8117, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8835, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3759, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9047, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0374, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8389, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6499, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3481, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7369, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8777, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9515, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6710, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0784, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.7101, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8378, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.4952, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0996, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2974, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5840, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1650, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2828, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0911, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7037, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.4860, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9623, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6905, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6815, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9030, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2467, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6322, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9259, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9137, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.4699, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7699, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.9535, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6921, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5009, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7177, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0598, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0424, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7446, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6057, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3134, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6540, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6704, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.4104, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1876, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7684, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8148, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0999, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5188, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.4446, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0781, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6171, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4278, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1359, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0531, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9118, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9927, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8862, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1537, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8804, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1423, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8532, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8294, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6158, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-5.4174, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9447, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9370, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8954, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6470, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2876, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2434, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3187, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9394, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6228, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1565, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8766, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5213, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1832, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8558, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3428, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4571, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2521, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1491, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.2849, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7535, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7399, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5793, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8973, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.6121, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0203, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7205, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1070, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6355, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1346, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7541, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6776, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1796, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2627, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0739, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1188, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2910, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1674, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9512, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7723, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.7886, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8240, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1475, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7294, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8066, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6685, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.4869, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3440, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9109, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2963, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6949, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7995, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6678, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6266, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 138.591064\n",
      "tensor(-3.8707, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1378, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.5438, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0514, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.6690, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5526, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2619, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0120, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.8141, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.6324, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0581, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2131, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5604, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.1402, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0795, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.3321, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0006, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8916, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1148, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1788, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.5442, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9023, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1600, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0820, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.2828, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0660, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.3924, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6196, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.4732, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0232, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-3.9308, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1468, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.0031, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9311, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-4.1015, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.2873, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Train for one epoch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Generate and save a batch of images from the VAE's latent space\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# generate_images(filename=f'sample_epoch_{epoch}.png')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Initialize training loss for the epoch\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Loop over all batches in the training dataset\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Move data to the device (GPU/CPU)\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Reset the gradients from the previous iteration\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Research/human-like/hl-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Research/human-like/hl-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Research/human-like/hl-env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Research/human-like/hl-env/lib/python3.12/site-packages/torchvision/datasets/mnist.py:143\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    139\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/Research/human-like/hl-env/lib/python3.12/site-packages/PIL/Image.py:3304\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3301\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrides\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires either tobytes() or tostring()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 3304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/human-like/hl-env/lib/python3.12/site-packages/PIL/Image.py:3151\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3147\u001b[0m         im\u001b[38;5;241m.\u001b[39mfrombytes(data, decoder_name, decoder_args)\n\u001b[1;32m   3148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[0;32m-> 3151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrombuffer\u001b[39m(\n\u001b[1;32m   3152\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m, size: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m], data, decoder_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any\n\u001b[1;32m   3153\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image:\n\u001b[1;32m   3154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3155\u001b[0m \u001b[38;5;124;03m    Creates an image memory referencing pixel data in a byte buffer.\u001b[39;00m\n\u001b[1;32m   3156\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.1.4\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3187\u001b[0m     _check_size(size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)  # Train for one epoch\n",
    "    # Generate and save a batch of images from the VAE's latent space\n",
    "    # generate_images(filename=f'sample_epoch_{epoch}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
