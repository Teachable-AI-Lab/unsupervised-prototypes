{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# import tsne\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# VaDE Model Definition\n",
    "# ------------------------------\n",
    "\n",
    "class VaDE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=500, latent_dim=10, n_clusters=10):\n",
    "        super(VaDE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_clusters = n_clusters\n",
    "        \n",
    "        # Encoder network\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder network\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # For MNIST, pixel values in [0,1]\n",
    "        )\n",
    "        \n",
    "        # GMM Prior Parameters:\n",
    "        # 1. Cluster prior logits; softmax gives pi (mixing coefficients)\n",
    "        self.pi_logits = nn.Parameter(torch.zeros(n_clusters))\n",
    "        # 2. Cluster means: shape (n_clusters, latent_dim)\n",
    "        self.mu_c = nn.Parameter(torch.zeros(n_clusters, latent_dim))\n",
    "        # 3. Cluster log variances: shape (n_clusters, latent_dim)\n",
    "        self.logvar_c = nn.Parameter(torch.zeros(n_clusters, latent_dim))  # Init 0 => variance 1\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar, z\n",
    "    \n",
    "    def gmm_params(self):\n",
    "        # Return the cluster prior probabilities (pi), means, and log variances.\n",
    "        pi = F.softmax(self.pi_logits, dim=0)  # (n_clusters,)\n",
    "        return pi, self.mu_c, self.logvar_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Helper Functions\n",
    "# ------------------------------\n",
    "\n",
    "def log_gaussian(z, mu, logvar):\n",
    "    \"\"\"\n",
    "    Compute the log probability of z under a Gaussian with parameters (mu, logvar).\n",
    "    z: (batch_size, latent_dim)\n",
    "    mu, logvar: (n_clusters, latent_dim)\n",
    "    Returns: log_prob of shape (batch_size, n_clusters)\n",
    "    \"\"\"\n",
    "    batch_size = z.size(0)\n",
    "    n_clusters = mu.size(0)\n",
    "    latent_dim = z.size(1)\n",
    "    \n",
    "    # Expand z to (batch_size, n_clusters, latent_dim)\n",
    "    z_expanded = z.unsqueeze(1).expand(batch_size, n_clusters, latent_dim)\n",
    "    mu_expanded = mu.unsqueeze(0).expand(batch_size, n_clusters, latent_dim)\n",
    "    logvar_expanded = logvar.unsqueeze(0).expand(batch_size, n_clusters, latent_dim)\n",
    "    \n",
    "    quadratic = ((z_expanded - mu_expanded) ** 2) / torch.exp(logvar_expanded)\n",
    "    log_prob = -0.5 * (latent_dim * np.log(2 * np.pi) + torch.sum(logvar_expanded, dim=2) + torch.sum(quadratic, dim=2))\n",
    "    return log_prob  # (batch_size, n_clusters)\n",
    "\n",
    "def gaussian_kl(mu, logvar, mu_c, logvar_c):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence between q(z|x) = N(mu, exp(logvar))\n",
    "    and each Gaussian N(mu_c, exp(logvar_c)) for every cluster.\n",
    "    Returns: (batch_size, n_clusters) tensor of KL values.\n",
    "    \"\"\"\n",
    "    batch_size = mu.size(0)\n",
    "    n_clusters = mu_c.size(0)\n",
    "    latent_dim = mu.size(1)\n",
    "    \n",
    "    mu_expanded = mu.unsqueeze(1).expand(batch_size, n_clusters, latent_dim)\n",
    "    logvar_expanded = logvar.unsqueeze(1).expand(batch_size, n_clusters, latent_dim)\n",
    "    mu_c_expanded = mu_c.unsqueeze(0).expand(batch_size, n_clusters, latent_dim)\n",
    "    logvar_c_expanded = logvar_c.unsqueeze(0).expand(batch_size, n_clusters, latent_dim)\n",
    "    \n",
    "    kl_element = 0.5 * (\n",
    "        logvar_c_expanded - logvar_expanded +\n",
    "        (torch.exp(logvar_expanded) + (mu_expanded - mu_c_expanded) ** 2) / torch.exp(logvar_c_expanded) - 1\n",
    "    )\n",
    "    kl = torch.sum(kl_element, dim=2)  # Sum over latent dimensions\n",
    "    return kl  # (batch_size, n_clusters)\n",
    "\n",
    "def vae_loss(x, x_recon, mu, logvar, z, model):\n",
    "    \"\"\"\n",
    "    Compute the VaDE loss which includes:\n",
    "      - Reconstruction loss: binary cross-entropy between x and its reconstruction.\n",
    "      - KL divergence: measures the difference between the encoder's distribution and the GMM prior.\n",
    "    \"\"\"\n",
    "    batch_size = x.size(0)\n",
    "    # Reconstruction loss (averaged over batch)\n",
    "    recon_loss = F.binary_cross_entropy(x_recon, x, reduction='sum') / batch_size\n",
    "    \n",
    "    # Get GMM parameters: pi, mu_c, logvar_c\n",
    "    pi, mu_c, logvar_c = model.gmm_params()  # pi: (n_clusters,), mu_c & logvar_c: (n_clusters, latent_dim)\n",
    "    \n",
    "    # For each sample, compute log probability under each cluster's Gaussian:\n",
    "    log_p_z_c = log_gaussian(z, mu_c, logvar_c)  # (batch_size, n_clusters)\n",
    "    log_pi = torch.log(pi + 1e-10)  # (n_clusters,)\n",
    "    log_p_zc = log_p_z_c + log_pi  # (batch_size, n_clusters)\n",
    "    \n",
    "    # Compute soft assignment: p(c|z) = softmax(log(pi * N(z|mu_c, sigma_c)))\n",
    "    p_c_z = F.softmax(log_p_zc, dim=1)  # (batch_size, n_clusters)\n",
    "    \n",
    "    # KL divergence between q(z|x) and each p(z|c)\n",
    "    kl_z = gaussian_kl(mu, logvar, mu_c, logvar_c)  # (batch_size, n_clusters)\n",
    "    \n",
    "    # Two components of the KL term:\n",
    "    # 1. Cluster assignment KL: sum_c p(c|z) log(p(c|z)/pi_c)\n",
    "    kl_cluster = torch.sum(p_c_z * (torch.log(p_c_z + 1e-10) - log_pi), dim=1)\n",
    "    # 2. Latent KL: sum_c p(c|z) * KL(q(z|x)||N(z; mu_c, sigma_c))\n",
    "    kl_latent = torch.sum(p_c_z * kl_z, dim=1)\n",
    "    \n",
    "    kl_term = torch.mean(kl_cluster + kl_latent)\n",
    "    \n",
    "    total_loss = recon_loss + kl_term\n",
    "    return total_loss, recon_loss, kl_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vade(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)  # data is already flattened by the transform\n",
    "        optimizer.zero_grad()\n",
    "        x_recon, mu, logvar, z = model(data)\n",
    "        loss, recon_loss, kl_term = vae_loss(data, x_recon, mu, logvar, z, model)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        # if batch_idx % 100 == 0:\n",
    "            # print(f\"Epoch {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}] \"\n",
    "                #   f\"Loss: {loss.item():.4f}, Recon: {recon_loss.item():.4f}, KL: {kl_term.item():.4f}\")\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    # print(f\"====> Epoch: {epoch} Average loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)  # data is already flattened by the transform\n",
    "        optimizer.zero_grad()\n",
    "        z, _ = model.encode(data)\n",
    "        x_recon = model.decode(z)\n",
    "        # loss, recon_loss, kl_term = vae_loss(data, x_recon, mu, logvar, z, model)\n",
    "        loss = F.binary_cross_entropy(x_recon, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        # if batch_idx % 100 == 0:\n",
    "            # print(f\"Epoch {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}] \"\n",
    "                #   f\"Loss: {loss.item():.4f}, Recon: {recon_loss.item():.4f}, KL: {kl_term.item():.4f}\")\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    # print(f\"====> Epoch: {epoch} Average loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_sne_on_test(model, test_loader, device):\n",
    "    latent_vectors = []\n",
    "    labels = []\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            mu, logvar = model.encode(data)\n",
    "            z = model.reparameterize(mu, logvar)\n",
    "        latent_vectors.append(z)\n",
    "        labels.append(target)\n",
    "        break  # Only need one batch\n",
    "    latent_vectors = torch.cat(latent_vectors, dim=0).cpu().numpy()\n",
    "    labels = torch.cat(labels, dim=0).cpu().numpy()\n",
    "    # tsne\n",
    "    tsne = TSNE(n_components=2)\n",
    "    # plot \n",
    "    latent_vectors = tsne.fit_transform(latent_vectors)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(latent_vectors[:, 0], latent_vectors[:, 1], c=labels, cmap='tab10')\n",
    "    plt.colorbar()\n",
    "    # save \n",
    "    plt.savefig('vade.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "lr = 2e-3\n",
    "latent_dim = 10\n",
    "n_clusters = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MNIST dataset: transform flattens the 28x28 image into a 784-dim vector.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "# Model and optimizer\n",
    "model = VaDE(input_dim=784, hidden_dim=500, latent_dim=latent_dim, n_clusters=n_clusters).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 26/469 [00:00<00:05, 81.40it/s]"
     ]
    }
   ],
   "source": [
    "for pretrain_epoch in range(10):\n",
    "    pretrain(model, device, train_loader, optimizer, pretrain_epoch)\n",
    "    t_sne_on_test(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 69.57it/s]\n",
      "100%|██████████| 469/469 [00:06<00:00, 69.20it/s]\n",
      "100%|██████████| 469/469 [00:06<00:00, 68.71it/s]\n",
      "100%|██████████| 469/469 [00:06<00:00, 68.18it/s]\n",
      "100%|██████████| 469/469 [00:06<00:00, 68.46it/s]\n",
      "100%|██████████| 469/469 [00:07<00:00, 63.58it/s]\n",
      "100%|██████████| 469/469 [00:07<00:00, 66.88it/s]\n",
      "100%|██████████| 469/469 [00:06<00:00, 68.05it/s]\n",
      "100%|██████████| 469/469 [00:07<00:00, 61.46it/s]\n",
      "100%|██████████| 469/469 [00:06<00:00, 70.34it/s]\n",
      "100%|██████████| 469/469 [00:07<00:00, 64.87it/s]\n",
      " 71%|███████   | 331/469 [00:05<00:02, 64.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mtrain_vade\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     t_sne_on_test(model, test_loader, device)\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# test_vade(model, device, test_loader)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtrain_vade\u001b[39m\u001b[34m(model, device, train_loader, optimizer, epoch)\u001b[39m\n\u001b[32m      2\u001b[39m model.train()\n\u001b[32m      3\u001b[39m train_loss = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# data is already flattened by the transform\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.13/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.13/site-packages/torchvision/datasets/mnist.py:143\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    139\u001b[39m img, target = \u001b[38;5;28mself\u001b[39m.data[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m.targets[index])\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    146\u001b[39m     img = \u001b[38;5;28mself\u001b[39m.transform(img)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.13/site-packages/PIL/Image.py:3338\u001b[39m, in \u001b[36mfromarray\u001b[39m\u001b[34m(obj, mode)\u001b[39m\n\u001b[32m   3335\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstrides\u001b[39m\u001b[33m'\u001b[39m\u001b[33m requires either tobytes() or tostring()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3336\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m3338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mraw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.13/site-packages/PIL/Image.py:3231\u001b[39m, in \u001b[36mfrombuffer\u001b[39m\u001b[34m(mode, size, data, decoder_name, *args)\u001b[39m\n\u001b[32m   3229\u001b[39m     args = mode, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m\n\u001b[32m   3230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _MAPMODES:\n\u001b[32m-> \u001b[39m\u001b[32m3231\u001b[39m     im = \u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3232\u001b[39m     im = im._new(core.map_buffer(data, size, decoder_name, \u001b[32m0\u001b[39m, args))\n\u001b[32m   3233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.13/site-packages/PIL/Image.py:3132\u001b[39m, in \u001b[36mnew\u001b[39m\u001b[34m(mode, size, color)\u001b[39m\n\u001b[32m   3130\u001b[39m         im.palette = ImagePalette.ImagePalette()\n\u001b[32m   3131\u001b[39m         color = im.palette.getcolor(color_ints)\n\u001b[32m-> \u001b[39m\u001b[32m3132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/dl/lib/python3.13/site-packages/PIL/Image.py:599\u001b[39m, in \u001b[36mImage._new\u001b[39m\u001b[34m(self, im)\u001b[39m\n\u001b[32m    596\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImagePalette\n\u001b[32m    598\u001b[39m         new.palette = ImagePalette.ImagePalette()\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m new.info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_vade(model, device, train_loader, optimizer, epoch)\n",
    "    t_sne_on_test(model, test_loader, device)\n",
    "    # test_vade(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
