{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from models.model import TreeVAE\n",
    "from utils.model_utils import construct_tree_fromnpy\n",
    "from utils.data_utils import get_data, get_gen\n",
    "from utils.training_utils import predict\n",
    "from utils.utils import cluster_acc\n",
    "\n",
    "checkpoint_path = 'models/experiments/mnist/20231025-175819_d6be9'  # ← 请替换为你的路径\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open(os.path.join(checkpoint_path, \"config.yaml\"), 'r') as f:\n",
    "    configs = yaml.load(f, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TreeVAE(**configs['training'])\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_path, \"model_weights.pt\"), map_location=device), strict=True)\n",
    "\n",
    "tree_structure = np.load(os.path.join(checkpoint_path, \"data_tree.npy\"), allow_pickle=True)\n",
    "model = construct_tree_fromnpy(model, tree_structure, configs)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, trainset_eval, testset = get_data(configs)\n",
    "gen_train_eval = get_gen(trainset_eval, configs, validation=True, shuffle=False)\n",
    "gen_test = get_gen(testset, configs, validation=True, shuffle=False)\n",
    "\n",
    "y_train = trainset_eval.dataset.targets[trainset_eval.indices].numpy()\n",
    "y_test = testset.dataset.targets[testset.indices].numpy()\n",
    "\n",
    "print(f\"data loaded | Train: {len(y_train)}, Test: {len(y_test)}\")\n",
    "\n",
    "train_acc = cluster_acc(y_train, trainset_eval.dataset.targets[trainset_eval.indices].numpy())\n",
    "test_acc = cluster_acc(y_test, testset.dataset.targets[testset.indices].numpy())\n",
    "\n",
    "print(f\"cluster accuracy | Train: {train_acc:.3f}, Test: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_pred = predict(gen_test, model, device)\n",
    "\n",
    "acc = cluster_acc(y_test, y_pred.numpy(), return_index=False)\n",
    "nmi = normalized_mutual_info_score(y_test, y_pred.numpy())\n",
    "\n",
    "print(f\"Clustering ACC: {acc:.4f}\")\n",
    "print(f\"NMI: {nmi:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = predict(gen_train_eval, model, device, 'bottom_up')[-1].cpu().numpy()\n",
    "z_test = predict(gen_test, model, device, 'bottom_up')[-1].cpu().numpy()\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(z_train, y_train)\n",
    "y_lp_pred = clf.predict(z_test)\n",
    "\n",
    "lp_acc = accuracy_score(y_test, y_lp_pred)\n",
    "print(f\"Linear Probe Accuracy: {lp_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train = predict(gen_train_eval, model, device, 'prob_leaves')\n",
    "prob_test = predict(gen_test, model, device, 'prob_leaves')\n",
    "\n",
    "leaf_test = prob_test.argmax(axis=1)\n",
    "\n",
    "def compute_dp_score(labels, leaves):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(i+1, len(labels)):\n",
    "            if labels[i] == labels[j]:\n",
    "                total += 1\n",
    "                if leaves[i] == leaves[j]:\n",
    "                    count += 1\n",
    "    return count / total if total > 0 else 0.0\n",
    "\n",
    "dp_score = compute_dp_score(y_test, leaf_test)\n",
    "print(f\"Decision Path Agreement: {dp_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======== TreeVAE Final Evaluation ========\")\n",
    "print(f\"Clustering ACC      : {acc:.4f}\")\n",
    "print(f\"NMI                 : {nmi:.4f}\")\n",
    "print(f\"Linear Probe ACC    : {lp_acc:.4f}\")\n",
    "print(f\"Decision Path Agree : {dp_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
